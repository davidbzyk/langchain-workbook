{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import FireCrawlLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Load environment variables from .env\n",
        "load_dotenv()\n",
        "\n",
        "# Define the persistent directory\n",
        "current_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "db_dir = os.path.join(current_dir, \"db\")\n",
        "persistent_directory = os.path.join(db_dir, \"chroma_db_firecrawl\")\n",
        "\n",
        "\n",
        "def create_vector_store():\n",
        "    \"\"\"Crawl the website, split the content, create embeddings, and persist the vector store.\"\"\"\n",
        "    # Define the Firecrawl API key\n",
        "    api_key = os.getenv(\"FIRECRAWL_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise ValueError(\"FIRECRAWL_API_KEY environment variable not set\")\n",
        "\n",
        "    # Step 1: Crawl the website using FireCrawlLoader\n",
        "    print(\"Begin crawling the website...\")\n",
        "    loader = FireCrawlLoader(\n",
        "        api_key=api_key, url=\"https://apple.com\", mode=\"scrape\")\n",
        "    docs = loader.load()\n",
        "    print(\"Finished crawling the website.\")\n",
        "\n",
        "    # Convert metadata values to strings if they are lists\n",
        "    for doc in docs:\n",
        "        for key, value in doc.metadata.items():\n",
        "            if isinstance(value, list):\n",
        "                doc.metadata[key] = \", \".join(map(str, value))\n",
        "\n",
        "    # Step 2: Split the crawled content into chunks\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    split_docs = text_splitter.split_documents(docs)\n",
        "\n",
        "    # Display information about the split documents\n",
        "    print(\"\\n--- Document Chunks Information ---\")\n",
        "    print(f\"Number of document chunks: {len(split_docs)}\")\n",
        "    print(f\"Sample chunk:\\n{split_docs[0].page_content}\\n\")\n",
        "\n",
        "    # Step 3: Create embeddings for the document chunks\n",
        "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "    # Step 4: Create and persist the vector store with the embeddings\n",
        "    print(f\"\\n--- Creating vector store in {persistent_directory} ---\")\n",
        "    db = Chroma.from_documents(\n",
        "        split_docs, embeddings, persist_directory=persistent_directory\n",
        "    )\n",
        "    print(f\"--- Finished creating vector store in {persistent_directory} ---\")\n",
        "\n",
        "\n",
        "# Check if the Chroma vector store already exists\n",
        "if not os.path.exists(persistent_directory):\n",
        "    create_vector_store()\n",
        "else:\n",
        "    print(\n",
        "        f\"Vector store {persistent_directory} already exists. No need to initialize.\")\n",
        "\n",
        "# Load the vector store with the embeddings\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "db = Chroma(persist_directory=persistent_directory,\n",
        "            embedding_function=embeddings)\n",
        "\n",
        "\n",
        "# Step 5: Query the vector store\n",
        "def query_vector_store(query):\n",
        "    \"\"\"Query the vector store with the specified question.\"\"\"\n",
        "    # Create a retriever for querying the vector store\n",
        "    retriever = db.as_retriever(\n",
        "        search_type=\"similarity\",\n",
        "        search_kwargs={\"k\": 3},\n",
        "    )\n",
        "\n",
        "    # Retrieve relevant documents based on the query\n",
        "    relevant_docs = retriever.invoke(query)\n",
        "\n",
        "    # Display the relevant results with metadata\n",
        "    print(\"\\n--- Relevant Documents ---\")\n",
        "    for i, doc in enumerate(relevant_docs, 1):\n",
        "        print(f\"Document {i}:\\n{doc.page_content}\\n\")\n",
        "        if doc.metadata:\n",
        "            print(f\"Source: {doc.metadata.get('source', 'Unknown')}\\n\")\n",
        "\n",
        "\n",
        "# Define the user's question\n",
        "query = \"Apple Intelligence?\"\n",
        "\n",
        "# Query the vector store with the user's question\n",
        "query_vector_store(query)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}