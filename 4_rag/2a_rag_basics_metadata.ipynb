{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Define the directory containing the text files and the persistent directory\n",
        "current_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "books_dir = os.path.join(current_dir, \"books\")\n",
        "db_dir = os.path.join(current_dir, \"db\")\n",
        "persistent_directory = os.path.join(db_dir, \"chroma_db_with_metadata\")\n",
        "\n",
        "print(f\"Books directory: {books_dir}\")\n",
        "print(f\"Persistent directory: {persistent_directory}\")\n",
        "\n",
        "# Check if the Chroma vector store already exists\n",
        "if not os.path.exists(persistent_directory):\n",
        "    print(\"Persistent directory does not exist. Initializing vector store...\")\n",
        "\n",
        "    # Ensure the books directory exists\n",
        "    if not os.path.exists(books_dir):\n",
        "        raise FileNotFoundError(\n",
        "            f\"The directory {books_dir} does not exist. Please check the path.\"\n",
        "        )\n",
        "\n",
        "    # List all text files in the directory\n",
        "    book_files = [f for f in os.listdir(books_dir) if f.endswith(\".txt\")]\n",
        "\n",
        "    # Read the text content from each file and store it with metadata\n",
        "    documents = []\n",
        "    for book_file in book_files:\n",
        "        file_path = os.path.join(books_dir, book_file)\n",
        "        loader = TextLoader(file_path)\n",
        "        book_docs = loader.load()\n",
        "        for doc in book_docs:\n",
        "            # Add metadata to each document indicating its source\n",
        "            doc.metadata = {\"source\": book_file}\n",
        "            documents.append(doc)\n",
        "\n",
        "    # Split the documents into chunks\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Display information about the split documents\n",
        "    print(\"\\n--- Document Chunks Information ---\")\n",
        "    print(f\"Number of document chunks: {len(docs)}\")\n",
        "\n",
        "    # Create embeddings\n",
        "    print(\"\\n--- Creating embeddings ---\")\n",
        "    embeddings = OpenAIEmbeddings(\n",
        "        model=\"text-embedding-3-small\"\n",
        "    )  # Update to a valid embedding model if needed\n",
        "    print(\"\\n--- Finished creating embeddings ---\")\n",
        "\n",
        "    # Create the vector store and persist it\n",
        "    print(\"\\n--- Creating and persisting vector store ---\")\n",
        "    db = Chroma.from_documents(\n",
        "        docs, embeddings, persist_directory=persistent_directory)\n",
        "    print(\"\\n--- Finished creating and persisting vector store ---\")\n",
        "\n",
        "else:\n",
        "    print(\"Vector store already exists. No need to initialize.\")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}